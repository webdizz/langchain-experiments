{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6cbd3c-1dc7-4f09-9e2e-db8e99089a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conversation buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243161b4-053e-4e80-a6f3-aff68fa3f83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24847731-9d0b-4a77-add3-26c85cbd826e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa6813a-4cc1-4927-aa54-b2d0dd5c10c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7b5a5e-d973-48e7-93da-308da2c43615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Izzet\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Izzet! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Izzet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d3ab64-7b2d-452b-90eb-cab4c3a94ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Izzet\n",
      "AI: Hello Izzet! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Izzet.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00060e5e-bf16-427d-bf1f-b01bc1f5cbef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Izzet\n",
      "AI: Hello Izzet! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI: Your name is Izzet.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005f4521-89fb-4b12-96eb-a59b30218a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Izzet\\nAI: Hello Izzet! It's nice to meet you. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is Izzet.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea38ab1e-de1b-41d0-85d6-fa854e869e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi\"}, {\"output\":\"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fbd03d9-f73f-4aac-8e18-5abe664ab584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Izzet\n",
      "AI: Hello Izzet! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI: Your name is Izzet.\n",
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9fb9ee-5217-401c-8300-1fc3a9a157c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi, my name is Izzet\\nAI: Hello Izzet! It's nice to meet you. How can I assist you today?\\nHuman: What is my name?\\nAI: Your name is Izzet.\\nHuman: Hi\\nAI: What's up\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c2b99-09ca-473d-8a38-d6053bae129f",
   "metadata": {},
   "source": [
    "## Usage of ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ef5801-c0fb-4de7-8a09-4527225c2857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "window_memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e45832-54e8-4d09-b563-e43f354d36b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})\n",
    "window_memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41794783-68f1-4bd7-84ce-7749ed3ee17b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21c3bdf6-b2de-4c20-b1ad-c00e5fd7276a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, memory=window_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c78af5c2-8f90-45ef-aa29-5303e5d19b41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b492c2e-aa0d-4b26-a55c-5005ed3a5591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c8b2ede-080d-495f-9f98-0538d78aae45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What is 1+1\\nAI: 1+1 is equal to 2.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19125de-831d-443c-a6d4-93285c78707a",
   "metadata": {},
   "source": [
    "## Usage of ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78507697-c340-4582-8f84-b596da307fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f7780dd-c0e8-4afb-85d4-42dfeb150b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f965d1ee-47e4-40ee-82ac-aad35c763149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "\n",
    "token_memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n",
    "token_memory.save_context(\n",
    "    {\"input\": \"Backpropagation is what?\"}, {\"output\": \"Beautiful!\"}\n",
    ")\n",
    "token_memory.save_context({\"input\": \"Chatbots are what?\"}, {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7385f886-2493-4dda-bcb2-dafd125dccfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eea68b-efeb-4895-8d8c-e21651df20f9",
   "metadata": {},
   "source": [
    "## Usage of ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af2cfb2c-482b-4450-8e67-7a67e3401bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7149d810-3834-4802-a763-5873bf1e5533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c02189a8-5daf-49e0-8bdc-5811fb6e49d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=30)\n",
    "summary_memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "summary_memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99cfc20f-b31e-466b-8836-55420df6b28f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: \\nThe human greets the AI and asks what is on the schedule for the day. The AI responds that there is a meeting with the product team at 8am, followed by time to work on the LangChain project, and then lunch with a customer at a nearby Italian restaurant to discuss the latest in AI. The human should bring their laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e9a34ff-965c-4a9e-88e3-5f0608f6604a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=summary_memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d83305a-e520-47a5-a98c-329f67484642",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human greets the AI and asks what is on the schedule for the day. The AI responds that there is a meeting with the product team at 8am, followed by time to work on the LangChain project, and then lunch with a customer at a nearby Italian restaurant to discuss the latest in AI. The human should bring their laptop to show the latest LLM demo.\n",
      "Human: What wouls be good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" A good demo to show would be the latest version of the LLM demo, which includes a demonstration of the AI's natural language processing capabilities. It also includes a demonstration of the AI's ability to understand and respond to user input.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What wouls be good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7fe1d8d-af20-4568-9498-db17c332c466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: \\nThe human greets the AI and asks what is on the schedule for the day. The AI responds that there is a meeting with the product team at 8am, followed by time to work on the LangChain project, and then lunch with a customer at a nearby Italian restaurant to discuss the latest in AI. The human should bring their laptop to show the latest LLM demo, which includes a demonstration of the AI's natural language processing capabilities and its ability to understand and respond to user input.\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279092a9-c5b4-41c3-b549-83e443d36c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
